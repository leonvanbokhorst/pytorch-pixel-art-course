# Guide: 05 Loading Model Parameters (state_dict)

This guide explains how to load saved model parameters (the `state_dict`) back into a model instance in PyTorch, as shown in `05_loading_model_parameters.py`.

**Core Concept:** Saving the `state_dict` allows you to persist the learned weights and buffers of your model. Loading the `state_dict` enables you to restore this learned state into a new instance of your model architecture, typically for inference or resuming training.

## Prerequisites for Loading

Before loading a `state_dict`, you need:

1. **The Model Class Definition:** The Python code defining the `nn.Module` subclass (e.g., `SimpleClassificationNet`) must be available in your current script (either defined directly or imported).
2. **The Saved `state_dict` File:** The `.pth` or `.pt` file generated by `torch.save(model.state_dict(), PATH)`.

## Steps to Load the `state_dict`

Loading the parameters involves these key steps:

1. **Instantiate the Model:** Create a _new_ instance of your model class. This instance will initially have random weights.

    ```python
    # Must use the *same* architecture as the saved weights
    model = SimpleClassificationNet(INPUT_FEATURES, HIDDEN_FEATURES, NUM_CLASSES)
    ```

2. **Load the Dictionary from File:** Use `torch.load()` to deserialize the dictionary object from your saved file.

    ```python
    LOAD_PATH = "saved_models/simple_classifier_weights.pth"
    state_dict = torch.load(LOAD_PATH)
    ```

    - **Device Mapping (Optional):** If you saved a model trained on a GPU and want to load it on a CPU (or vice-versa), you can use the `map_location` argument: `state_dict = torch.load(LOAD_PATH, map_location=torch.device('cpu'))`.
3. **Load Dictionary into Model:** Use the instantiated model's `.load_state_dict()` method, passing the loaded dictionary.

    ```python
    model.load_state_dict(state_dict)
    ```

    - **How it Works:** This method iterates through the provided `state_dict` and copies the parameter/buffer values into the corresponding layers/attributes of the `model` instance, matching them based on the dictionary keys (parameter names like `'layer_1.weight'`).
    - **`strict=True` (Default):** By default, this method expects the keys in the loaded `state_dict` to exactly match the keys returned by `model.state_dict()`. If there are missing keys (e.g., you added a layer to your model definition) or unexpected keys (e.g., the saved dictionary is from a different model), it will raise a `RuntimeError`. This helps catch errors caused by architecture mismatches. Set `strict=False` to load only matching keys, ignoring others (use with caution).

4. **Set to Evaluation Mode:** If you are loading the model for inference or evaluation (which is the most common reason), immediately call `model.eval()` to set dropout and batch normalization layers to evaluation mode.

    ```python
    model.eval()
    ```

## Code Walkthrough

The script `05_loading_model_parameters.py` performs these steps:

```python
# Script Snippet:
# 1. Instantiate model
loaded_model = SimpleClassificationNet(...)

if os.path.exists(LOAD_PATH):
    # 2. Load state_dict from file
    state_dict = torch.load(LOAD_PATH)

    # 3. Load state_dict into model
    loaded_model.load_state_dict(state_dict)

    # 4. Set to evaluation mode
    loaded_model.eval()

    # Now ready for inference:
    # with torch.no_grad():
    #     output = loaded_model(some_input)
else:
    print("File not found...")
```

## Architecture Must Match

It is critical that the architecture of the model you instantiate (`SimpleClassificationNet` in this case) **exactly matches** the architecture that was used when the `state_dict` was originally saved. If the layers, names, or sizes differ, `load_state_dict` (with `strict=True`) will fail because the dictionary keys won't match.

## Summary

Loading a saved `state_dict` into a PyTorch model involves: 1. Instantiating the model architecture, 2. Loading the saved dictionary using `torch.load(PATH)`, 3. Copying the parameters into the model instance using `model.load_state_dict(state_dict)`, and 4. Setting the model to evaluation mode with `model.eval()` if performing inference. This process restores the learned parameters, allowing you to reuse the trained model.
